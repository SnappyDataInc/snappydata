# Do not change the way of queries, sparkProperties, sparkSqlProperties. Just change the values inside strings

#queries to be run
queries=1-2-3-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22
#queries=16

sparkProperties="--driver-memory 2g --conf spark.executor.memory=10g --conf spark.network.timeout=300s --conf spark.driver.maxResultSize=2g"

#spark.sql.crossJoin.enabled=true
sparkSqlProperties="spark.sql.shuffle.partitions=3,spark.sql.inMemoryColumnarStorage.compressed=false"

#location of checkout
SnappyData=/home/kishor/snappy/SPARK/spark-2.0.1-bin-hadoop2.7

buckets=3
#Machine Setup
master=pnq-kbachhav3
slaves=(pnq-kbachhav3)
client=pnq-kbachhav3

# location of jar which has TPCH related class files
TPCHJar=/home/kishor/snappy/snappydata/load_snappydata/cluster/build-artifacts/scala-2.11/libs/snappydata-cluster_2.11-0.6-tests.jar

#Size of the TPCH data. Do not chage format
dataSize=1GB

#Location of the TPCH Data. Make sure directory name is same as the dataSize specified above
dataDir=dataDir=/home/kishor/snappy/

#Location where final output will be collected
outputLocation=/home/kishor/snappy/TPCH_APP/TPCH_OUTPUT/spark

#Whether to collect results
ResultCollection=false

#warmUpIterations
WarmupRuns=5
#Average Runs
AverageRuns=10
