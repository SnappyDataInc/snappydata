# Do not change the way of queries, sparkProperties, sparkSqlProperties. Just change the values inside strings

#queries to be run
queries="\"1,3,4,5,6,7,8,10,11,12,13,14,15,16,17,18,19,20,22\""


#spark Properties spefied in lead
#spark-executor-cores is not specified as it will be equal to the number of workers available
#spark-executor-cores has nothing to do with CPU cores available.
sparkProperties="-spark.network.timeout=300s -spark.driver.maxResultSize=2g -spark.shuffle.sort.bypassMergeThreshold=3"

#Spark Sql properties are specified while executing query
sparkSqlProperties="\"spark.sql.shuffle.partitions=4 spark.sql.inMemoryColumnarStorage.compressed=false\""

#location of checkout
SnappyData=/home/kishor/snappy/snappy-commons

#I have total 32 CPU cores available. hence chose nearest low prime number
buckets_Order_Lineitem=29

#Cusotmer, PArt, PArtSupp are small column tables. Its bucket count is also set to less no.
buckets_Cust_Part_PartSupp=7

#Machine Setup
locator=localhost
leads=localhost
servers=(localhost)

#Server Memmory to be used
serverMemory="-J-Xmx10g"

# location of jar which has TPCH related class files
TPCHJar=/home/kishor/snappy/snappy-commons/snappy-tools/build-artifacts/scala-2.10/libs/snappy-tools_2.10-0.1.0-SNAPSHOT-tests.jar

#Size of the TPCH data. Do not chage format
dataSize=1GB

#Location of the TPCH Data. Make sure directory name is same as the dataSize specified above
dataDir=/home/kishor/snappy/TPCH_APP/TPCH_Data/$dataSize

#Location where final output will be collected
outputLocation=/home/kishor/snappy/TPCH_APP/TPCH_OUTPUT/SNAPPY

#Whether to generate query plan
queryPlan=false
