# Do not change the way of queries, sparkProperties, sparkSqlProperties. Just change the values inside strings

#queries to be run
queries="\"1,3,4,5,6,7,8,10,11,12,13,14,15,16,17,18,19,20,22\""


#spark Properties spefied in lead
#spark-executor-cores is not specified as it will be equal to the number of workers available
#spark-executor-cores has nothing to do with CPU cores available.
sparkProperties="-spark.network.timeout=300s -spark.driver.maxResultSize=2g -spark.shuffle.sort.bypassMergeThreshold=3"

#Spark Sql properties are specified while executing query
#spark.sql.inMemoryColumnarStorage.compressed=false . Its default value is also false hence not added

sparkSqlProperties="\"spark.sql.shuffle.partitions=4\""

#location of checkout
SnappyData=/users/snappy/snappydata

#I have totoal 32 CPU cores available. hence chose nearest low prime number
NoOfBuckets=29

#Machine Setup
locator=localhost
leads=localhost
servers=(localhost)

#Server Memmory to be used
serverMemory="-J-Xmx10g"

# location of jar which has TPCH related class files
TPCHJar=/users/snappy/snappydata/snappy-tools/build-artifacts/scala-2.10/libs/snappy-tools_2.10-0.1.0-SNAPSHOT-tests.jar

#Size of the TPCH data. Do not chage format
dataSize=1GB

#Location of the TPCH Data. Make sure directory name is same as the dataSize specified above
dataDir=/users/snappy/data/$dataSize

#Location where final output will be collected
outputLocation=/users/snappy/output/snappy

#Whether to generate query plan
queryPlan=false
