hydra.Prms-testRequirement = "Test to verify cluster recovery when a new server node is added in the existing cluster.";
hydra.Prms-testDescription = "The test starts a cluster ,populates data ,after which data count is taken for later validation,
then in the running cluster a new node is added, then rebalance procedure is called and issues  abrupt server kill commands
in middle of rebalance.After some time couple of nodes are killed randomly ,then at the end cluster is restarted and data validation is done. ";

INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/topology_1.inc;

//threadGroups
INCLUDE $JTESTS/io/snappydata/hydra/cdcConnector/threadGroups.inc;

//Initial threadGroups
INITTASK    taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = initSnappyArtifacts
            runMode = always
            threadGroups = snappyThreads,snappyInitThread,snappyTaskThread1,snappyTaskThread2,snappyTaskThread3,snappyTaskThread4,snappyTaskThread5,snappyHAThread;

INITTASK    taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_recordProcessIDWithHost
            runMode = always
            threadGroups = snappyThreads,snappyInitThread,snappyTaskThread1,snappyTaskThread2,snappyTaskThread3,snappyTaskThread4,snappyTaskThread5,snappyHAThread;

/*
INITTASK    taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSQLScripts
            io.snappydata.hydra.cluster.SnappyPrms-sqlScriptNames = createFewTables.sql
            io.snappydata.hydra.cluster.SnappyPrms-dataLocation = ${dataFilesLocation}
            threadGroups = snappyInitThread;
*/
// Store data count of all the tables loaded.
INITTASK    taskClass  = io.snappydata.hydra.cdcConnector.SnappyCDCTest taskMethod  = storeDataCount
            threadGroups = snappyInitThread;

INITTASK    taskClass  = io.snappydata.hydra.cdcConnector.SnappyCDCTest taskMethod  = validateDataCount
            threadGroups = snappyInitThread;

//Add a new server node
INITTASK    taskClass  = io.snappydata.hydra.cdcConnector.SnappyCDCTest taskMethod  = addNewNode
           // io.snappydata.hydra.cdcConnector.SnappyCDCPrms-nodeConfig="dev10 -dir=/nfs/users/spillai/dev10 -heap-size=5g -memory-size=5g "
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-nodeName = ${newNode}
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-snappyFileLoc = ${snappyPath}
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-nodeType = servers
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-isNewNodeFirst = false
            threadGroups = snappyInitThread;

INITTASK    taskClass  = io.snappydata.hydra.cdcConnector.SnappyCDCTest taskMethod  = validateDataCount
            threadGroups = snappyInitThread;

// trigger rebalance
TASK       taskClass  = io.snappydata.hydra.cdcConnector.SnappyCDCTest taskMethod  = performRebalance
           threadGroups = snappyTaskThread1
           maxTimesToRun = 1
           maxThreads = 1;

//While rebalance is on,issue mean kill.
TASK       taskClass  = io.snappydata.hydra.cdcConnector.SnappyCDCTest taskMethod  = meanKillProcesses
           io.snappydata.hydra.cdcConnector.SnappyCDCPrms-nodeType = servers
           io.snappydata.hydra.cdcConnector.SnappyCDCPrms-snappyFileLoc = ${snappyPath}
           threadGroups = snappyTaskThread2
           maxTimesToRun = 1
           maxThreads = 1;

//Keep ingesting data in parallel ,while the above two tasks are in progress.
TASK       taskClass  = io.snappydata.hydra.cdcConnector.SnappyCDCTest taskMethod  = HydraTask_runIngestionApp
           io.snappydata.hydra.cdcConnector.SnappyCDCPrms-threadCnt = 5
           io.snappydata.hydra.cdcConnector.SnappyCDCPrms-initStartRange = 1000001
           io.snappydata.hydra.cdcConnector.SnappyCDCPrms-initEndRange = 2000001
           io.snappydata.hydra.cdcConnector.SnappyCDCPrms-dataLocation = ${insertQueryPath1}
           threadGroups = snappyTaskThread3
           maxTimesToRun = 1
           maxThreads = 1;

//issue meankill on couple of nodes.
TASK       taskClass  = io.snappydata.hydra.cdcConnector.SnappyCDCTest taskMethod  = meanKillProcesses
           io.snappydata.hydra.cdcConnector.SnappyCDCPrms-nodeType = servers
           io.snappydata.hydra.cdcConnector.SnappyCDCPrms-snappyFileLoc = ${snappyPath}
           io.snappydata.hydra.cdcConnector.SnappyCDCPrms-numNodes = 2
           startInterval = 10  //after 45 mins kill 2 nodes.
           endInterval   = 10
           maxTimesToRun = 1
           threadGroups = snappyTaskThread2
           maxThreads = 1;



CLOSETASK  taskClass  = io.snappydata.hydra.cdcConnector.SnappyCDCTest taskMethod  = storeDataCount
           threadGroups = snappyInitThread;

//restart the cluster.
CLOSETASK  taskClass  = io.snappydata.hydra.cdcConnector.SnappyCDCTest taskMethod  = HydraTask_clusterRestart
           io.snappydata.hydra.cdcConnector.SnappyCDCPrms-snappyFileLoc = ${snappyPath}
           io.snappydata.hydra.cdcConnector.SnappyCDCPrms-nodeType = allNodes
           io.snappydata.hydra.cdcConnector.SnappyCDCPrms-isStopStartCluster=false
           threadGroups = snappyInitThread;

CLOSETASK   taskClass  = io.snappydata.hydra.cdcConnector.SnappyCDCTest taskMethod  = validateDataCount
            threadGroups = snappyInitThread;

io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar;
io.snappydata.hydra.cluster.SnappyPrms-isLongRunningTest = true;
hydra.Prms-maxResultWaitSec = 3600;
//hydra.Prms-totalTaskTimeSec = 3600;
